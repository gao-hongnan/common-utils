version: '3.8'
x-logging:
  &default-logging
  options:
    max-size: "100m"
    max-file: "5"
  driver: json-file
services:
  db:
    image: postgres:${POSTGRES_VERSION}
    logging: *default-logging
    container_name: mlflow-db
    restart: unless-stopped
    # https://docs.docker.com/compose/environment-variables/set-environment-variables/
    environment:
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    ports:
      - "${POSTGRES_PORT}:5432" # HOST:CONTAINER
    volumes:
      # db: must match the volume name below
      - db:/var/lib/postgresql/data
    networks:
      - mlflow-gaohn
  mlflow:
    image: "${MLFLOW_IMAGE}:${MLFLOW_TAG}"
    build:
      context: .
      dockerfile: Dockerfile
    logging: *default-logging
    restart: unless-stopped
    depends_on:
      - db
    ports:
      - "${MLFLOW_PORT}:5000" # HOST:CONTAINER
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/mlflow
      - MLFLOW_ARTIFACT_STORE_URI=${MLFLOW_ARTIFACT_STORE_URI}
    command:
      [
        "mlflow",
        "server",
        "--backend-store-uri",
        "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/mlflow",
        "--default-artifact-root",
        "${MLFLOW_ARTIFACT_STORE_URI}",
        "--host",
        "0.0.0.0"
      ]
    networks:
      - mlflow-gaohn
volumes:
  # For my MLflow setup, let's assume you have a directory in your host
  # machine where you want to persist data. You can create a volume for your
  # PostgreSQL database to store data, and also,
  # you might want to create a separate volume for your MLflow artifacts
  # if they're not stored on an external service like Google Cloud Storage.
  workspace:
    name: ${WORKSPACE_DOCKER_MOUNT}
  db:
    name: ${DB_DOCKER_MOUNT}
networks:
  mlflow-gaohn:
    driver: bridge # default
