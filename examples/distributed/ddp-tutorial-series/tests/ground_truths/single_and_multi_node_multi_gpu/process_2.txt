2023-09-16 13:28:24 [INFO]: Initializing the following Environment variables: InitEnvArgs(master_addr='172.23.0.69', master_port='44781')
2023-09-16 13:28:24 [INFO]: Process group arguments: InitProcessGroupArgs(rank=2, world_size=4, backend='nccl', init_method='env://')
2023-09-16 13:28:27 [INFO]: Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-16 13:28:27 [INFO]: Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-16 13:28:28 [INFO]: Initialized process group: Rank 2 out of 4.
2023-09-16 13:28:28 [INFO]: Distributed info: DistributedInfo(node_rank=1, num_nodes=2, num_gpus_per_node=2, num_gpus_in_curr_node_rank=2, is_dist_available=True, is_dist_initialized=True, process_id=1050317, global_rank=2, world_size=4, local_rank=0, device=device(type='cuda', index=0), node_hostname='x1000c1s3b0n0')
2023-09-16 13:28:28 [INFO]: node_rank: 1
2023-09-16 13:28:28 [INFO]: num_nodes: 2
2023-09-16 13:28:28 [INFO]: num_gpus_per_node: 2
2023-09-16 13:28:28 [INFO]: num_gpus_in_curr_node_rank: 2
2023-09-16 13:28:28 [INFO]: is_dist_available: True
2023-09-16 13:28:28 [INFO]: is_dist_initialized: True
2023-09-16 13:28:28 [INFO]: process_id: 1050317
2023-09-16 13:28:28 [INFO]: global_rank: 2
2023-09-16 13:28:28 [INFO]: world_size: 4
2023-09-16 13:28:28 [INFO]: local_rank: 0
2023-09-16 13:28:28 [INFO]: device: cuda:0
2023-09-16 13:28:28 [INFO]: node_hostname: x1000c1s3b0n0
2023-09-16 13:28:28 [INFO]:
+-------------+-------------+---------------------+------------------------------+---------------------+-----------------------+--------------+---------------+--------------+--------------+----------+-----------------+
|   node_rank |   num_nodes |   num_gpus_per_node |   num_gpus_in_curr_node_rank | is_dist_available   | is_dist_initialized   |   process_id |   global_rank |   world_size |   local_rank | device   | node_hostname   |
+=============+=============+=====================+==============================+=====================+=======================+==============+===============+==============+==============+==========+=================+
|           1 |           2 |                   2 |                            2 | True                | True                  |      1050317 |             2 |            4 |            0 | cuda:0   | x1000c1s3b0n0   |
+-------------+-------------+---------------------+------------------------------+---------------------+-----------------------+--------------+---------------+--------------+--------------+----------+-----------------+
2023-09-16 13:28:28 [INFO]: Distributed info: DistributedInfo(node_rank=1, num_nodes=2, num_gpus_per_node=2, num_gpus_in_curr_node_rank=2, is_dist_available=True, is_dist_initialized=True, process_id=1050317, global_rank=2, world_size=4, local_rank=0, device=device(type='cuda', index=0), node_hostname='x1000c1s3b0n0')
2023-09-16 13:28:29 [INFO]: Starting training with Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: Reducer buckets have been rebuilt in this iteration.
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 0 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5412 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 0 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5247 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 1 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5245 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 1 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5098 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 2 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4991 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 2 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4834 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 3 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5182 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 3 | Batchsize: 32 | Steps: 16 | Average Loss: 0.5027 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 4 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4613 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 4 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4482 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 5 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4645 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 5 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4510 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 6 | Batchsize: 32 | Steps: 16 | Average Loss: 0.4034 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 6 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3916 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 7 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3861 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 7 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3754 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 8 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3623 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 8 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3519 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 9 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3307 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 9 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3218 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 10 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3332 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 10 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3243 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 11 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3299 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 11 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3213 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 12 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2929 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 12 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2853 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 13 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2796 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 13 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2729 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 14 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3085 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 14 | Batchsize: 32 | Steps: 16 | Average Loss: 0.3013 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [TRAIN: NODE1 GPU2] Epoch 15 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2554 | Learning Rate: 0.001
2023-09-16 13:28:30 [INFO]: [VALID: NODE1 GPU2] Epoch 15 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2491 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 16 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2437 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 16 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2381 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 17 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2415 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 17 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2354 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 18 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2285 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 18 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2234 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 19 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2265 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 19 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2213 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 20 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2239 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 20 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2188 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 21 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2244 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 21 | Batchsize: 32 | Steps: 16 | Average Loss: 0.2194 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 22 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1913 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 22 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1872 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 23 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1974 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 23 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1934 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 24 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1926 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 24 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1886 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 25 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1922 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 25 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1886 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 26 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1634 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 26 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1604 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 27 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1736 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 27 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1703 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 28 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1631 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 28 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1605 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 29 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1443 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 29 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1418 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 30 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1561 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 30 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1538 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 31 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1542 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 31 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1517 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 32 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1337 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 32 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1316 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 33 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1481 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 33 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1459 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 34 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1299 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 34 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1283 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 35 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1321 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 35 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1303 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 36 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1270 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 36 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1252 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 37 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1200 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 37 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1186 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 38 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1183 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 38 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1171 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 39 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1168 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 39 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1155 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 40 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1183 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 40 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1169 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 41 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1075 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 41 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1064 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 42 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1145 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 42 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1134 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 43 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1070 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 43 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1058 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 44 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1101 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 44 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1091 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 45 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1008 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 45 | Batchsize: 32 | Steps: 16 | Average Loss: 0.0999 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 46 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1141 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 46 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1130 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 47 | Batchsize: 32 | Steps: 16 | Average Loss: 0.0934 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 47 | Batchsize: 32 | Steps: 16 | Average Loss: 0.0927 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 48 | Batchsize: 32 | Steps: 16 | Average Loss: 0.0993 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 48 | Batchsize: 32 | Steps: 16 | Average Loss: 0.0985 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [TRAIN: NODE1 GPU2] Epoch 49 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1094 | Learning Rate: 0.001
2023-09-16 13:28:31 [INFO]: [VALID: NODE1 GPU2] Epoch 49 | Batchsize: 32 | Steps: 16 | Average Loss: 0.1086 | Learning Rate: 0.001
