{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtwTIjo7oOuB"
   },
   "source": [
    "# Encoder-only transformer model for AG News classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "o5eW3azllzRd"
   },
   "source": [
    "In this notebook, I train a encoder-only transformer to do text classification on the AG_NEWS dataset.\n",
    "Text classification seems to be a pretty simple task, and using transformer is probably overkill. But this is my first time implementing the transformer structure from scratch (including the self-attention module), and it was fun :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "id": "Mtq3abS2lL_i"
   },
   "outputs": [],
   "source": [
    "# some commands in th is notebook require torchtext 0.12.0\n",
    "# !pip install  torchtext --upgrade --quiet\n",
    "# !pip install torchdata --quiet\n",
    "# !pip install torchinfo --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1650896386699,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "bQEBuaIm5s9R",
    "outputId": "ccbc67d9-5437-43f6-e385-740925cbe04a"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "from rich.pretty import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchdata\n",
    "import torchinfo\n",
    "import torchtext\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed: Optional[int] = 1992, seed_torch: bool = True) -> int:\n",
    "    \"\"\"\n",
    "    Seed all random number generators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int, optional\n",
    "        Seed number to be used, by default 1992.\n",
    "    seed_torch : bool, optional\n",
    "        Whether to seed PyTorch or not, by default True.\n",
    "    \"\"\"\n",
    "    # fmt: off\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)        # set PYTHONHASHSEED env var at fixed value\n",
    "    np.random.seed(seed)                            # numpy pseudo-random generator\n",
    "    random.seed(seed)                               # python's built-in pseudo-random generator\n",
    "\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        # torch.manual_seed may call manual_seed_all but calling it again here\n",
    "        # to make sure it gets called at least once\n",
    "        torch.cuda.manual_seed_all(seed)             # pytorch (both CPU and CUDA)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.enabled = False\n",
    "    # fmt: on\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "seed_all(42, seed_torch=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmM0VcYnCC8M"
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "executionInfo": {
     "elapsed": 2641,
     "status": "ok",
     "timestamp": 1650896389339,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "7UdYsN6J5uke"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "num_classes = len(set([label for (label, text) in train_iter]))\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1650896389339,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "HchVgEXWlqLz",
    "outputId": "5ed8c7ef-783b-4ffd-8724-7216b44c8c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see an example of the dateset\n",
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "6DeTWUptkYnG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert the labels to be in range(0, num_classes)\n",
    "y_train = torch.tensor([label-1 for (label, text) in train_iter])\n",
    "y_test  = torch.tensor([label-1 for (label, text) in test_iter])\n",
    "\n",
    "# There are many \"\\\\\" in the texts in the AG_news dataset, we get rid of them.\n",
    "train_iter = ((label, text.replace(\"\\\\\", \" \")) for label, text in train_iter)\n",
    "test_iter  = ((label, text.replace(\"\\\\\", \" \")) for label, text in test_iter)\n",
    "\n",
    "# tokenize the texts, and truncate the number of words in each text to max_seq_len\n",
    "max_seq_len = 100\n",
    "x_train_texts = [tokenizer(text.lower())[0:max_seq_len]\n",
    "                 for (label, text) in train_iter]\n",
    "x_test_texts  = [tokenizer(text.lower())[0:max_seq_len]\n",
    "                 for (label, text) in test_iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1650896399478,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "MYVE8HSGkYnH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# build the vocabulary and word-to-integer map\n",
    "counter = collections.Counter()\n",
    "for text in x_train_texts:\n",
    "    counter.update(text)\n",
    "\n",
    "vocab_size = 15000\n",
    "most_common_words = np.array(counter.most_common(vocab_size - 2))\n",
    "vocab = most_common_words[:,0]\n",
    "\n",
    "# indexes for the padding token, and unknown tokens\n",
    "PAD = 0\n",
    "UNK = 1\n",
    "word_to_id = {vocab[i]: i + 2 for i in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "executionInfo": {
     "elapsed": 2463,
     "status": "ok",
     "timestamp": 1650896401940,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "I7-4KQI8kYnH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# map the words in the training and test texts to integers\n",
    "x_train = [torch.tensor([word_to_id.get(word, UNK) for word in text])\n",
    "           for text in x_train_texts]\n",
    "x_test  = [torch.tensor([word_to_id.get(word, UNK) for word in text])\n",
    "          for text in x_test_texts]\n",
    "x_test = torch.nn.utils.rnn.pad_sequence(x_test,\n",
    "                                batch_first=True, padding_value = PAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650896401940,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "hJe8LAUNkYnI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# constructing the dataset in order to be compatible with torch.utils.data.Dataloader\n",
    "class AGNewsDataset:\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.features[item], self.labels[item]\n",
    "\n",
    "\n",
    "train_dataset = AGNewsDataset(x_train, y_train)\n",
    "test_dataset  = AGNewsDataset(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650896401941,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "ov3tX4sRkYnI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# collate_fn to be used in torch.utils.data.DataLoader().\n",
    "# It pads the texts in each batch such that they have the same sequence length.\n",
    "def pad_sequence(batch):\n",
    "    texts  = [text for text, label in batch]\n",
    "    labels = torch.tensor([label for text, label in batch])\n",
    "    texts_padded = torch.nn.utils.rnn.pad_sequence(texts,\n",
    "                                batch_first=True, padding_value = PAD)\n",
    "    return texts_padded, labels\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
    "                        collate_fn = pad_sequence)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True,\n",
    "                        collate_fn = pad_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNVoCKz0CM3g"
   },
   "source": [
    "## Building the encoder-only transformer model for text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650896401941,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "gxqdJRLXyHin"
   },
   "outputs": [],
   "source": [
    "# from transformer_blocks import Encoder\n",
    "# One can also import Encoder from transformer_blocks.py in my Github repository.\n",
    "# I copied the code here so that this notebook is self-contained.\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0 # check the h number\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        #print(x_query[0][0])\n",
    "        #time.sleep(100)\n",
    "        nbatch = x_query.size(0) # get batch size\n",
    "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
    "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
    "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "\n",
    "\n",
    "        # 2) Attention\n",
    "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
    "\n",
    "        # 3) Mask out padding tokens and future tokens\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
    "        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(p_atten)\n",
    "\n",
    "        # x dimensions: nbatch * h * seq_len * d_k\n",
    "        x = torch.matmul(p_atten, value)\n",
    "\n",
    "        # x now has dimensions:nbtach * seq_len * d_embed\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "\n",
    "        return self.linear(x) # final linear layer\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "  def __init__(self, dim, dropout):\n",
    "      super().__init__()\n",
    "      self.drop = nn.Dropout(dropout)\n",
    "      self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "  def forward(self, x, sublayer):\n",
    "      return x + self.drop(sublayer(self.norm(x)))\n",
    "\n",
    "# I simply let the model learn the positional embeddings in this notebook, since this\n",
    "# almost produces identital results as using sin/cosin functions embeddings, as claimed\n",
    "# in the original transformer paper. Note also that in the original paper, they multiplied\n",
    "# the token embeddings by a factor of sqrt(d_embed), which I do not do here.\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        x = self.tok_embed(input)\n",
    "\n",
    "        x_pos = self.pos_embed[:, :x.size(1), :]\n",
    "        x = self.dropout(x + x_pos)\n",
    "\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, mask)\n",
    "        print(x[0][0])\n",
    "        time.sleep(100)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
    "    def __init__(self, config):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
    "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self-attention\n",
    "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
    "        # position-wise fully connected feed-forward layer\n",
    "        return self.residual2(x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(config)\n",
    "        self.linear = nn.Linear(config.d_embed, num_classes)\n",
    "\n",
    "    def forward(self, x, pad_mask=None):\n",
    "        x = self.encoder(x, pad_mask)\n",
    "        return  self.linear(torch.mean(x,-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650896401941,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "gxYYnrC-FAgI"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    encoder_vocab_size: int\n",
    "    d_embed: int\n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_encoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "\n",
    "def make_model(config):\n",
    "    model = Transformer(config, num_classes).to(DEVICE)\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HdgZPJBoKY2"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650896401941,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "Ydp6IfBrkYnL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    losses, acc, count = [], 0, 0\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for idx, (x, y)  in  pbar:\n",
    "        optimizer.zero_grad()\n",
    "        features= x.to(DEVICE)\n",
    "        labels  = y.to(DEVICE)\n",
    "        pad_mask = (features == PAD).view(features.size(0), 1, 1, features.size(-1))\n",
    "        pred = model(features, pad_mask)\n",
    "\n",
    "        loss = loss_fn(pred, labels).to(DEVICE)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        acc += (pred.argmax(1) == labels).sum().item()\n",
    "        count += len(labels)\n",
    "        # report progress\n",
    "        if idx>0 and idx%50 == 0:\n",
    "            pbar.set_description(f'train loss={loss.item():.4f}, train_acc={acc/count:.4f}')\n",
    "    return np.mean(losses), acc/count\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs):\n",
    "    for ep in range(epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader)\n",
    "        val_loss, val_acc = evaluate(model, test_loader)\n",
    "        print(f'ep {ep}: val_loss={val_loss:.4f}, val_acc={val_acc:.4f}')\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            features = x_test.to(DEVICE)\n",
    "            labels  = y_test.to(DEVICE)\n",
    "            pad_mask = (features == PAD).view(features.size(0), 1, 1, features.size(-1))\n",
    "            pred = model(features, pad_mask)\n",
    "            loss = loss_fn(pred,labels).to(DEVICE)\n",
    "            losses.append(loss.item())\n",
    "            acc = (pred.argmax(1) == labels).sum().item()\n",
    "            count = len(labels)\n",
    "    return np.mean(losses), acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3022,
     "status": "ok",
     "timestamp": 1650896404954,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "tIau66WRlzRm",
    "outputId": "51942f59-a52e-4aa2-f9f6-def535ee51b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModelConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">encoder_vocab_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15000</span>, <span style=\"color: #808000; text-decoration-color: #808000\">d_embed</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #808000; text-decoration-color: #808000\">d_ff</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">h</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">N_encoder</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">max_seq_len</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dropout</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mModelConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mencoder_vocab_size\u001b[0m=\u001b[1;36m15000\u001b[0m, \u001b[33md_embed\u001b[0m=\u001b[1;36m32\u001b[0m, \u001b[33md_ff\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mh\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mN_encoder\u001b[0m=\u001b[1;36m1\u001b[0m, \u001b[33mmax_seq_len\u001b[0m=\u001b[1;36m100\u001b[0m, \u001b[33mdropout\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "Transformer                                        --\n",
      "├─Encoder: 1-1                                     3,200\n",
      "│    └─Embedding: 2-1                              480,000\n",
      "│    └─ModuleList: 2-2                             --\n",
      "│    │    └─EncoderBlock: 3-1                      12,704\n",
      "│    └─Dropout: 2-3                                --\n",
      "│    └─LayerNorm: 2-4                              64\n",
      "├─Linear: 1-2                                      132\n",
      "===========================================================================\n",
      "Total params: 496,100\n",
      "Trainable params: 496,100\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "config = ModelConfig(encoder_vocab_size = vocab_size,\n",
    "                     d_embed = 32,\n",
    "                     d_ff = 4*32,\n",
    "                     h = 1,\n",
    "                     N_encoder = 1,\n",
    "                     max_seq_len = max_seq_len,\n",
    "                     dropout = 0.0\n",
    "                     )\n",
    "pprint(config)\n",
    "\n",
    "model = make_model(config)\n",
    "print(torchinfo.summary(model))\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39274,
     "status": "ok",
     "timestamp": 1650896444224,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "Qo7RYNx0lzRm",
    "outputId": "14e319f1-fb24-4411-aac0-8fe983a7f267",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5583,  0.1366, -0.2859, -0.3117,  0.3013, -0.2570,  0.8979, -0.5129,\n",
      "         0.8320,  0.4529,  0.5040,  0.4293,  0.7893,  1.5377, -0.8081,  0.3100,\n",
      "         1.5381, -0.9857, -0.7400, -0.0164,  0.2468,  1.2153, -0.1118,  1.2446,\n",
      "        -0.1677,  0.2441,  0.3550,  0.1295, -0.1954,  0.1115,  0.7696, -0.5586],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(model, train_loader, test_loader, epochs\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "\u001b[1;32m/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, train_loader, test_loader, epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         train_loss, train_acc \u001b[39m=\u001b[39m train_epoch(model, train_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         val_loss, val_acc \u001b[39m=\u001b[39m evaluate(model, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mep \u001b[39m\u001b[39m{\u001b[39;00mep\u001b[39m}\u001b[39;00m\u001b[39m: val_loss=\u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, val_acc=\u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m labels  \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m pad_mask \u001b[39m=\u001b[39m (features \u001b[39m==\u001b[39m PAD)\u001b[39m.\u001b[39mview(features\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, features\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pred \u001b[39m=\u001b[39m model(features, pad_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(pred, labels)\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dps/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dps/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, pad_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x, pad_mask)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(torch\u001b[39m.\u001b[39mmean(x,\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dps/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/dps/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb Cell 21\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     x \u001b[39m=\u001b[39m layer(x, mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39mprint\u001b[39m(x[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gaohn/gaohn/common-utils/transformer/transformer/Encoder_only_transformer_AG_News_classification.ipynb#X24sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, train_loader, test_loader, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBSr0A9noh2i"
   },
   "source": [
    "## News classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650896444225,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "uaAPcoPTkYnM",
    "outputId": "25e191cd-854e-490e-872c-769efe32c62d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Sci/Tec news\n"
     ]
    }
   ],
   "source": [
    "ag_news_label = {1: \"World\",\n",
    "                 2: \"Sports\",\n",
    "                 3: \"Business\",\n",
    "                 4: \"Sci/Tec\"}\n",
    "\n",
    "def classify_news(news):\n",
    "    x_text = tokenizer(news.lower())[0:max_seq_len]\n",
    "    x_int = torch.tensor([[word_to_id.get(word, UNK) for word in x_text]]).to(DEVICE)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(x_int).argmax(1).item() + 1\n",
    "    print(f\"This is a {ag_news_label[pred]} news\")\n",
    "\n",
    "# The model correctly classifies a theoretical physics news as Sci/Tec news, :-)\n",
    "news = \"\"\"The conformal bootstrapDavid Poland1,2and David Simmons-Duﬃn2*The conformal bootstrap was\n",
    "proposed in the 1970s as a strategy for calculating the properties of second-order phasetransitions.\n",
    "After spectacular success elucidating two-dimensional systems, little progress was made on systems in\n",
    " higher dimensions until a recent renaissance beginning in 2008. We report on some of the main results and\n",
    "  ideas from thisrenaissance, focusing on new determinations of critical exponents and correlation\n",
    "  functions in the three-dimensional Ising and O(N) models.\n",
    "\"\"\"\n",
    "classify_news(news)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Encoder_only_transformer_AG_News_classification.ipynb",
   "provenance": [
    {
     "file_id": "1P7oU2EWQ1Qk17N9NutZv9FV1a_hMGUoR",
     "timestamp": 1647373127550
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
